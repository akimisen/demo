## SpecStory

## 番茄小说爬虫代码整理 (3/2/2025, 4:37:35 PM)

_**User**_

@https://blog.csdn.net/Myc970223/article/details/141276413 能否参考这个页面，整理出该站点的内容爬取代码

---

_**Assistant**_

# 番茄小说爬虫代码实现

根据提供的博客文章，我可以整理出一个完整的番茄小说爬虫代码。这个爬虫主要解决了番茄小说网站的文字加密问题。

下面是完整的代码实现：

```python:Untitled-1
import requests
import parsel
import os

def get_font_mapping():
    """
    获取字体映射关系
    实际使用时需要下载字体文件并分析映射关系
    这里使用示例映射字典
    """
    # 这里应该是通过分析字体文件得到的映射关系
    # 实际使用时需要下载woff2文件并使用FontCreator等工具分析
    # 下面是示例映射字典，实际使用时需要替换为真实的映射关系
    font_mapping = {
        # 示例: unicode码 -> 实际字符
        '59336': '的',
        '58652': '一',
        '58659': '是',
        '59335': '了',
        '58674': '我',
        # ... 更多映射关系
    }
    return font_mapping

def get_novel_info(url):
    """获取小说信息和章节列表"""
    headers = {
        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36 Edg/127.0.0.0',
    }
    
    response = requests.get(url=url, headers=headers)
    selector = parsel.Selector(response.text)
    
    # 获取小说标题
    novel_title = selector.css('h1.novel-title::text').get().strip()
    
    # 获取章节列表
    title_list = selector.css('.chapter-item .chapter-item-title::text').getall()
    url_list = selector.css('.chapter-item .chapter-item-title::attr(href)').getall()
    
    # 构建完整URL
    full_url_list = []
    for chapter_url in url_list:
        if chapter_url.startswith('http'):
            full_url_list.append(chapter_url)
        else:
            full_url_list.append(f'https://fanqienovel.com{chapter_url}')
    
    return novel_title, title_list, full_url_list

def decrypt_content(text, font_mapping):
    """解密章节内容"""
    novel_content = ''
    for line in text:
        for char in line:
            try:
                # 尝试查找字符的Unicode映射
                word = font_mapping[str(ord(char))]
                novel_content += word
            except:
                # 如果找不到映射，保留原字符
                novel_content += char
        novel_content += '\n'
    return novel_content

def get_chapter_content(url, font_mapping):
    """获取章节内容"""
    headers = {
        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36 Edg/127.0.0.0',
    }
    
    response = requests.get(url=url, headers=headers)
    selector = parsel.Selector(response.text)
    
    # 获取章节标题
    chapter_title = selector.css('.muye-reader-title::text').get().strip()
    
    # 获取章节内容
    text = selector.css('.muye-reader-content.noselect div div p::text').getall()
    
    # 解密内容
    content = decrypt_content(text, font_mapping)
    
    return chapter_title, content

def save_to_file(novel_title, chapter_title, content, save_dir='novels'):
    """保存章节内容到文件"""
    # 创建保存目录
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)
    
    # 创建小说目录
    novel_dir = os.path.join(save_dir, novel_title)
    if not os.path.exists(novel_dir):
        os.makedirs(novel_dir)
    
    # 保存章节内容
    file_path = os.path.join(novel_dir, f"{chapter_title}.txt")
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write(content)
    
    print(f"已保存: {chapter_title}")

def main():
    # 小说目录页URL
    novel_url = 'https://fanqienovel.com/page/7081535608648109069'  # 替换为实际的小说URL
    
    # 获取字体映射关系
    font_mapping = get_font_mapping()
    
    # 获取小说信息和章节列表
    novel_title, chapter_titles, chapter_urls = get_novel_info(novel_url)
    print(f"开始下载小说: {novel_title}, 共{len(chapter_titles)}章")
    
    # 下载每一章内容
    for i, (title, url) in enumerate(zip(chapter_titles, chapter_urls)):
        print(f"正在下载第{i+1}章: {title}")
        try:
            chapter_title, content = get_chapter_content(url, font_mapping)
            save_to_file(novel_title, chapter_title, content)
        except Exception as e:
            print(f"下载失败: {title}, 错误: {e}")
    
    print(f"小说《{novel_title}》下载完成!")

if __name__ == "__main__":
    main()
```

## 代码说明

1. **字体映射获取**：
   - 实际使用时需要下载字体文件(woff2)并使用FontCreator等工具分析
   - 示例代码中的映射字典需要替换为实际分析得到的映射关系

2. **主要功能**：
   - 获取小说信息和章节列表
   - 解密章节内容（处理文字加密）
   - 保存章节内容到本地文件

3. **使用方法**：
   - 替换`novel_url`为实际要爬取的小说URL
   - 完善`get_font_mapping()`函数，添加实际的字体映射关系
   - 运行脚本即可下载小说

4. **注意事项**：
   - 需要分析每本小说使用的字体文件，不同小说可能使用不同的字体映射
   - 实际使用时可能需要处理请求频率限制、IP封禁等问题
   - 建议添加随机延时和代理IP功能以避免被封

这个代码是基于博客文章中的思路整理的，实际使用时可能需要根据网站的变化进行调整。

[参考链接](https://blog.csdn.net/Myc970223/article/details/141276413)

---

_**User**_

@https://www.cnblogs.com/ruichow/p/18209338 这个页面好像更全面一些，看一下有没有需要修正的地方

---

_**Assistant**_



---



---

